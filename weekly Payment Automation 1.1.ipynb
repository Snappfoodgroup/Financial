{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce4116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e83b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Load:\n",
    "    \n",
    "    def __init__(self , path = r'C:\\Users\\snappfood\\Desktop\\financial\\23-29april' , excel_name = 'Payment 20220423 - 20220429.xlsx'):\n",
    "        self.path = path\n",
    "        self.excel_name = excel_name\n",
    "        \n",
    "    def load(self):\n",
    "        data = pd.read_excel(f'{self.path}/{self.excel_name}',sheet_name=None)\n",
    "        for name in data.keys():\n",
    "            data[name].rename(str.lower, axis='columns', inplace=True)\n",
    "            \n",
    "        return data       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a8f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = Load(path=r'C:\\Users\\snappfood\\Desktop\\financial\\28may - 3jun' , excel_name = 'Payment 20220528 - 20220603.xlsx')\n",
    "data = load_data.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688852e3",
   "metadata": {},
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c614930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    \n",
    "    def __init__ (self , data = data , output = r'C:\\Users\\snappfood\\Desktop\\financial\\23-29april\\output'):\n",
    "        \n",
    "        self.data = data\n",
    "        self.output = output\n",
    "        \n",
    "    def wrong_shaba(self):\n",
    "        ''' Detect all the wrong sheba numbers in excel file '''\n",
    "        counter = 0\n",
    "        wrong_sheba_tehran=pd.DataFrame()\n",
    "        for i in range(data['tehran'].shape[0]):\n",
    "            if len(str(data['tehran']['sheba number'].iloc[i]))!=26:\n",
    "                wrong_sheba_tehran=wrong_sheba_tehran.append(data['tehran'].iloc[i])\n",
    "                counter+=1\n",
    "        self.wrong_sheba_tehran = wrong_sheba_tehran\n",
    "        \n",
    "        if counter!=0:\n",
    "            print(f'There was {counter} incorrect sheba number(s)')\n",
    "            wrong_sheba_tehran.to_excel(f'{self.output}/wrong_sheba_tehran.xlsx')  \n",
    "            \n",
    "        return counter , self.wrong_sheba_tehran\n",
    "    \n",
    "    def sheba_merge(self):\n",
    "        '''merged datafarme which gained from wrong_sheba function and if it has a identical match in orginal excel file\n",
    "        detect their biker ids'''\n",
    "        \n",
    "        wrong_sheba=self.wrong_sheba_tehran[['biker id','sheba number','lastname','total payable']]\n",
    "        noSheba=self.data['no sheba'][['biker id','sheba number','lastname','total payable']]\n",
    "        \n",
    "        wrong_sheba.fillna(0,inplace=True)\n",
    "        noSheba.fillna(0, inplace=True)\n",
    "        \n",
    "        #Full join on biker_id\n",
    "        #___________________________________________________________________________#\n",
    "        no_sheba_merged=pd.merge(wrong_sheba,noSheba,on='biker id',how='outer')\n",
    "        #___________________________________________________________________________#\n",
    "        \n",
    "        missed_no_sheba = pd.DataFrame()\n",
    "        #change if command:\n",
    "        if no_sheba_merged['sheba number_x'].isnull().sum()== 0 and no_sheba_merged['sheba number_y'].isnull().sum()== 0:\n",
    "            print('wrong sheba numbers are the same in both files')\n",
    "        else:\n",
    "            missed_no_sheba=missed_no_sheba.append(no_sheba_merged[no_sheba_merged['sheba number_y'].isnull()])\n",
    "            missed_no_sheba=missed_no_sheba.append(no_sheba_merged[no_sheba_merged['sheba number_x'].isnull()])\n",
    "            print(f'There was {missed_no_sheba.shape[0]} missed sheba numbers')\n",
    "            return  missed_no_sheba\n",
    "        \n",
    "        #return no_sheba_merged\n",
    "        \n",
    "    def dublicate(self , attributes =['sheba number' , 'biker id' , 'cellphone']):\n",
    "        ''' found any duplicated values in the selected futures and return their excel files'''\n",
    " \n",
    "        for feature in attributes:\n",
    "\n",
    "            df = self.data['tehran'][feature].dropna(axis = 0) \n",
    "            duplicated = pd.DataFrame()\n",
    "            if df.unique().shape[0] == df.shape[0]:\n",
    "                print(f'No duplicated {feature} founded')\n",
    "            else:\n",
    "                filt = df.duplicated(keep=False)==True\n",
    "                duplicated= self.data['tehran'].loc[list(df[filt].index)]\n",
    "                duplicated.to_excel(f'{self.output}/duplicated_{feature}.xlsx')\n",
    "                print(f'There was {duplicated[feature].unique().shape[0]} duplicated values in the {feature}')\n",
    "                        \n",
    "               # values=df.value_counts().to_dict()\n",
    "                #keys=list(values.keys())\n",
    "                #for i in range(len(values)):\n",
    "                 #   if values[keys[i]]>1:\n",
    "                  #      duplicated =duplicated.append(data['tehran'][data['tehran'][feature]==keys[i]])\n",
    "                #duplicated.to_excel(f'{self.output}/duplicated_{feature}.xlsx')\n",
    "                  \n",
    "    def payment_comp(self):\n",
    "        '''check the positive_payable datas with payment datas '''\n",
    "        \n",
    "        pos_payable=data['tehran'][data['tehran']['total payable']>0]\n",
    "        neg_payable=data['tehran'][data['tehran']['total payable']<=0]\n",
    "        self.neg_payable = neg_payable.copy()\n",
    "        \n",
    "        pos_payable_correct_sheba =pos_payable[~pos_payable['biker id'].isin(data['no sheba']['biker id'])]\n",
    "        tehran_positive_payable=pos_payable_correct_sheba[['biker id', 'total payable', 'lastname','sheba number']]\n",
    "        \n",
    "        pay_data =data['payment'][['biker id', 'total payable', 'lastname','firstname' ,'sheba number']]  \n",
    "        pay_comp = pd.merge(tehran_positive_payable, pay_data, on='biker id', how='left')\n",
    "        \n",
    "        if pay_comp['sheba number_y'].isnull().sum()!=0:\n",
    "            \n",
    "            missed_biker_from_payment =pay_comp[pay_comp['sheba number_y'].isnull()]\n",
    "            missed_biker_from_payment.to_excel(f'{self.output}/missed_in_payment_bikers.xlsx')\n",
    "        else:\n",
    "            print('biker payments in tehran and payment sheets are the same')\n",
    "            \n",
    " \n",
    "                \n",
    "        tehran_comp_data=data['tehran']\n",
    "        noSheba_comp_data=data['no sheba']\n",
    "        payment_comp_data=data['payment']\n",
    "        #positive payments and valid sheba number\n",
    "        filt = (tehran_comp_data['total payable']>0) & (~tehran_comp_data['biker id'].isin(list(noSheba_comp_data['biker id'])))\n",
    "        tehran_comp_data[filt]\n",
    "        \n",
    "        self.tehran_comp_data=tehran_comp_data[filt][['biker id', 'sheba number','total payable','firstname','lastname','express trips']]\n",
    "        self.payment_comp_data=payment_comp_data[['biker id', 'sheba number','total payable','firstname','lastname','express trips']]\n",
    "               \n",
    "        \n",
    "        return self.tehran_comp_data , self.payment_comp_data , self.neg_payable \n",
    "      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90b7025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was 208 incorrect sheba number(s)\n",
      "wrong sheba numbers are the same in both files\n",
      "No duplicated sheba number founded\n",
      "No duplicated biker id founded\n",
      "No duplicated cellphone founded\n",
      "biker payments in tehran and payment sheets are the same\n"
     ]
    }
   ],
   "source": [
    "load_data = Load(path=r'C:\\Users\\snappfood\\Desktop\\financial\\28may - 3jun' , excel_name = 'Payment 20220528 - 20220603.xlsx')\n",
    "data = load_data.load()\n",
    "preprocess = Preprocess(data=data , output=r'C:\\Users\\snappfood\\Desktop\\financial\\28may - 3jun\\output' )\n",
    "counter , wrong_sheba_tehran  = preprocess.wrong_shaba()\n",
    "no_sheba_merged  = preprocess. sheba_merge()\n",
    "dublicate = preprocess . dublicate()\n",
    "tehran_comp , payment_comp , neg_payable  = preprocess.payment_comp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd538e",
   "metadata": {},
   "source": [
    "## 2.Check with DataBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e1e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Comparison(Preprocess):\n",
    "    \n",
    "    def __init__(self ,  start_date , end_date ,data = data ,neg_payable = neg_payable ,output = r'C:\\Users\\snappfood\\Desktop\\financial\\23-29april\\output' ):\n",
    "        \n",
    "        self.output = output\n",
    "        self.data=data\n",
    "        self.neg_payable = neg_payable\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        \n",
    "    def connection(self):\n",
    "        server = '79.175.132.125,1410'\n",
    "        database = 'express_db'\n",
    "        username = 'ExpressAnalyst'\n",
    "        password = '^cVGXN6q[nY#[-GE'\n",
    "        Driver = 'SQL Server'\n",
    "        cnxn = pyodbc.connect(\n",
    "                'DRIVER={SQL Server};SERVER=' + server + ';DATABASE=' + database + ';UID=' + username + ';PWD=' + password)\n",
    "        cursor = cnxn.cursor()\n",
    "        return cursor \n",
    "\n",
    "    def database_check(self):\n",
    "        '''check the obtained datas with databse'''\n",
    "\n",
    "        query_1=f\"\"\"SELECT user_id,\n",
    "           count(distinct id) as tedad\n",
    "            from  express_db..trip\n",
    "            where trip_status like '%Delivered%'\n",
    "              and created_at >= '{self.start_date}'\n",
    "              and created_at < '{self.end_date}'\n",
    "              and user_id <> 1\n",
    "              -- and t.city_id = 1\n",
    "\n",
    "            group by user_id\"\"\"\n",
    "\n",
    "        cursor=self.connection()\n",
    "        cursor.execute(query_1)\n",
    "        online_data=cursor.fetchall()  \n",
    "        online_df = pd.DataFrame.from_records(online_data , columns = ['biker id' , 'db_trips'])\n",
    "        online_df.to_csv(f'{self.output}/database_data.csv') \n",
    "        self.online_df = online_df.copy()\n",
    "        \n",
    "        #filtered negative payables and incorrect shebas from DB datas:\n",
    "        \n",
    "        edited_df=online_df[~online_df['biker id'].isin(list(data['no sheba']['biker id']))]\n",
    "        edited_df=online_df[~online_df['biker id'].isin(list(self.neg_payable['biker id']))]\n",
    "        self.edited_df= edited_df.copy()\n",
    "        \n",
    "        Payments=self.data['payment'][['biker id', 'express trips']]\n",
    "        bikers_no_payment=pd.merge(self.edited_df,Payments,on='biker id',how='left')\n",
    "        \n",
    "        self.bikers_no_payment = bikers_no_payment.copy()\n",
    "        \n",
    "        bikers_no_payment.to_csv(f'{self.output}/bikers.csv')\n",
    "        \n",
    "        missed_biker_from_file = bikers_no_payment[bikers_no_payment['express trips'].isnull()]\n",
    "\n",
    "        \n",
    "        return self.online_df , self.edited_df , self.bikers_no_payment , missed_biker_from_file\n",
    "    \n",
    "    \n",
    "    def diff_trips(self):\n",
    "        '''this function retrive payment sheet of excel and database table to check number of trips in both and compare them '''\n",
    "        \n",
    "        self.bikers_no_payment.fillna(0, inplace=True)\n",
    "        \n",
    "        self.bikers_no_payment['diff']=abs(self.bikers_no_payment['express trips']-self.bikers_no_payment['db_trips'])\n",
    "        \n",
    "        self.bikers_no_payment=self.bikers_no_payment[~self.bikers_no_payment['biker id'].isin(list(self.data['no sheba']['biker id']))]\n",
    "        self.bikers_no_payment=self.bikers_no_payment[~self.bikers_no_payment['biker id'].isin(list(self.neg_payable['biker id']))]\n",
    "        \n",
    "        \n",
    "        self.bikers_no_payments=self.bikers_no_payment[self.bikers_no_payment['diff']>4].sort_values(by=['biker id'])\n",
    "        \n",
    "        #save:\n",
    "        self.bikers_no_payments.to_excel(f'{self.output}/Diff_Trips_DB.xlsx')\n",
    "\n",
    "        \n",
    "        return self.bikers_no_payments\n",
    "    \n",
    "    \n",
    "    def diff_date(self):\n",
    "        self.biker_id_list = self.bikers_no_payments['biker id'].to_list()\n",
    "        self.biker_id_list.remove(20008)\n",
    "        \n",
    "         \n",
    "        start_date = dt.datetime.strptime(self.start_date , '%Y-%m-%d')\n",
    "        created_date = start_date - dt.timedelta(1)    \n",
    "       \n",
    "        delivery_date = start_date \n",
    "        \n",
    "        delivery_date = str(delivery_date.date())\n",
    "        \n",
    "        query_2 = f'''select t.id,\n",
    "                       t.user_id,\n",
    "                       t.created_at,\n",
    "                       t.delivered_at,\n",
    "                       t.trip_status,\n",
    "                       t.zf_order_id\n",
    "                        from express_db..trip t\n",
    "                        where t.created_at >= '{created_date}'\n",
    "                          and t.delivered_at >= '{self.start_date}'\n",
    "                          and t.created_at < '{self.end_date}'\n",
    "                        --and t.city_id = 1\n",
    "                          and t.user_id  in {tuple(self.biker_id_list)}\n",
    "                          and cast(t.created_at as date) <> cast(t.delivered_at as date)\n",
    "                        ---order by t.created_at '''\n",
    "\n",
    "\n",
    "        cursor=self.connection()\n",
    "        cursor.execute(query_2)\n",
    "        online_data=cursor.fetchall() \n",
    "        online_df = pd.DataFrame.from_records(online_data , columns = ['id' , 'biker_id','created_at' , 'deliverd_at' , 'trip_status' , 'zf_order_id'])\n",
    "        online_df['allowed_diff'] = online_df['deliverd_at']-online_df['created_at'] < dt.timedelta(1)\n",
    "        #just start and end of interval \n",
    "        end_date = dt.datetime.strptime(self.end_date , '%Y-%m-%d')\n",
    "        start_date = dt.datetime.strptime(self.start_date,'%Y-%m-%d')\n",
    "        \n",
    "        filt=(online_df['created_at'].apply(lambda x: x.date())==created_date.date()) | (online_df['created_at'].apply(lambda x: x.date())==end_date.date()-dt.timedelta(1)) & (online_df['allowed_diff']==True)\n",
    "        \n",
    "        online_df=online_df[filt]\n",
    "        new_diff =  self.bikers_no_payments.copy() \n",
    "        \n",
    "        \n",
    "        if online_df.shape[0]!=0:\n",
    "            print(f'There are {online_df.shape[0]} trips with edge of interval travels ')\n",
    "            \n",
    "         \n",
    "        for i in online_df['biker_id'].unique():\n",
    "            filt = new_diff['biker id'] == i\n",
    "            filt1 = online_df['biker_id'] == i\n",
    "            n = online_df[filt1].shape[0]\n",
    "            ind = new_diff[filt].index[0]\n",
    "            new_diff.loc[ind , 'diff'] -= n  \n",
    "        \n",
    "        self.new_diff = new_diff\n",
    "        return online_df , self.new_diff\n",
    "    \n",
    "    def multi_delivered_check(self):\n",
    "        \n",
    "        final = self.new_diff.copy()\n",
    "        query_3 = f\"\"\"select tsh.trip_id,\n",
    "               t.user_id,\n",
    "               t.trip_status,\n",
    "               tsh.to_status,\n",
    "               t.city_id , \n",
    "               tsh.from_biker_id\n",
    "            from express_db..TripStatusHistory tsh\n",
    "                     join express_db..trip t\n",
    "                          on t.id = tsh.trip_id\n",
    "            where tsh.created_at >= '{self.start_date}'\n",
    "              and tsh.created_at < '{self.end_date}'\n",
    "              and tsh.from_biker_id in {tuple(self.biker_id_list)}\n",
    "            -- and t.city_id=1\n",
    "            group by tsh.trip_id, t.user_id, t.trip_status, t.city_id , tsh.from_biker_id , tsh.to_status\n",
    "            having count(iif(tsh.to_status like '%delivered%', tsh.id, null)) > 0 \"\"\"\n",
    "        \n",
    "        cursor=self.connection()\n",
    "        cursor.execute(query_3)\n",
    "        online_data=cursor.fetchall() \n",
    "        f_df = pd.DataFrame.from_records(online_data, columns =['trip id' , 'user id' , 'status', 'status tsh','city id' ,'biker id tsh' ])\n",
    "        all_df = f_df.copy()\n",
    "        #detect number of trips which deliverd with muliple bikers\n",
    "        filt = all_df['user id'] != all_df['biker id tsh'] \n",
    "        x= all_df[filt]\n",
    "        x = x.groupby(['biker id tsh'])['status'].count()\n",
    "        \n",
    "            \n",
    "        #Decrease values from the original dataframe\n",
    "        \n",
    "        for i in x.index:\n",
    "            filt = final['biker id'] == i\n",
    "            ind = final[filt].index[0]\n",
    "            n = x[i]\n",
    "            final.loc[ind , 'diff'] -= n\n",
    "            \n",
    "        \n",
    "        #delete 20008 biker id:\n",
    "        filte = final['biker id'] == 20008\n",
    "        index= final[filte].index[0]\n",
    "        final.drop(index , axis = 0 , inplace=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        return all_df , final , x \n",
    "    \n",
    "\n",
    "        \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7abb93ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 trips with edge of interval travels \n"
     ]
    }
   ],
   "source": [
    "#date from sat to sat\n",
    "comparison = Comparison(output=r'C:\\Users\\snappfood\\Desktop\\financial\\28may - 3jun\\output' , data=data , start_date = '2022-05-28' , end_date = '2022-06-04')\n",
    "df , edited_df , bikers_no_payment ,missed_biker_from_file  = comparison.database_check()\n",
    "bikers_no_payments = comparison.diff_trips()\n",
    "df , new_diff = comparison.diff_date()\n",
    "all_df, final , x = comparison.multi_delivered_check()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde6e1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biker id</th>\n",
       "      <th>db_trips</th>\n",
       "      <th>express trips</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>1314</td>\n",
       "      <td>263</td>\n",
       "      <td>268.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5437</th>\n",
       "      <td>1476</td>\n",
       "      <td>340</td>\n",
       "      <td>345.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3268</th>\n",
       "      <td>4827</td>\n",
       "      <td>303</td>\n",
       "      <td>308.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13735</td>\n",
       "      <td>309</td>\n",
       "      <td>314.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>20028</td>\n",
       "      <td>297</td>\n",
       "      <td>302.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3117</th>\n",
       "      <td>22158</td>\n",
       "      <td>365</td>\n",
       "      <td>370.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>26516</td>\n",
       "      <td>234</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>28957</td>\n",
       "      <td>312</td>\n",
       "      <td>319.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682</th>\n",
       "      <td>42242</td>\n",
       "      <td>184</td>\n",
       "      <td>189.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>46453</td>\n",
       "      <td>228</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      biker id  db_trips  express trips  diff\n",
       "868       1314       263          268.0   0.0\n",
       "5437      1476       340          345.0   1.0\n",
       "3268      4827       303          308.0   0.0\n",
       "71       13735       309          314.0   1.0\n",
       "4310     20028       297          302.0   2.0\n",
       "3117     22158       365          370.0   1.0\n",
       "3536     26516       234          239.0   1.0\n",
       "297      28957       312          319.0   0.0\n",
       "2682     42242       184          189.0   1.0\n",
       "677      46453       228          233.0   0.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21551631",
   "metadata": {},
   "source": [
    "## Financial Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0204cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Finance(Comparison):\n",
    "    def __init__(self , data = data ,path=r'E:/Weekly Payments/tasvieh_file/' , name='tasvieh'   ):\n",
    "        \n",
    "        self.path = path\n",
    "        \n",
    "        self.data = data\n",
    "        self.name = name\n",
    "        if self.name[-4:]!= 'xlsx':\n",
    "            self.name = name + '.xlsx'\n",
    "        \n",
    "    \n",
    "    def calculation(self):\n",
    "        \n",
    "        f_df=pd.read_excel(f'{self.path}/{self.name}' , sheet_name ='pattern-1' , header= 1 )\n",
    "        \n",
    "        self.tasvieh_data=f_df.copy(deep=True)\n",
    "        \n",
    "        self.tasvieh_data.rename(columns={'مبلغ':'payable','نام و نام خانوادگی ذینفع':'name','شبای مقصد':'sheba number' }, inplace=True, errors='raise')\n",
    "        self.tasvieh_data.drop(columns=['شماره سپرده ی مبدا','شماره مشتری','کد بانک مقصد','شرح تراکنش','تاریخ ارسال','شناسه واریز(اختیاری)'], inplace=True, errors='raise')\n",
    "        \n",
    "        self.payment_comp = self.data['payment']\n",
    "        #Totman to rial\n",
    "        self.payment_comp['total payable'] = payment_comp['total payable']*10\n",
    "        #sort values by sheba:\n",
    "        self.tasvieh_data.sort_values(by='sheba number', inplace=True)\n",
    "        self.payment_comp.sort_values(by='sheba number', inplace=True)\n",
    "        self.tasvieh_data.reset_index(drop=True, inplace=True)\n",
    "        self.payment_comp.reset_index(drop=True, inplace=True)\n",
    "        if self.tasvieh_data.shape[0] == self.payment_comp.shape[0]:\n",
    "            print('Same number of sheba in both files')\n",
    "    \n",
    "        \n",
    "        \n",
    "        self.tasvieh_data['concated']=self.tasvieh_data['sheba number'].apply(str)+'_'+self.tasvieh_data['name'].apply(str)+'_'+self.tasvieh_data['payable'].apply(str)\n",
    "        \n",
    "        \n",
    "        self.payment_comp['concated']=self.payment_comp['sheba number'].apply(str)+'_'+self.payment_comp['firstname'].apply(str)+' '+self.payment_comp['lastname'].apply(str)+'_'+self.payment_comp['total payable'].apply(str)\n",
    "        \n",
    "        tas_comp=self.tasvieh_data[['sheba number','name' , 'payable','concated']]\n",
    "        pay_comp=self.payment_comp[['sheba number','lastname' ,'firstname', 'total payable','concated' ]]\n",
    "        \n",
    "        megered_tasvieh = pd.merge(tas_comp,pay_comp, on='sheba number', how='outer')\n",
    "        \n",
    "        \n",
    "        if megered_tasvieh['payable'].sum()/ megered_tasvieh['total payable'].sum() == 1  or megered_tasvieh['payable'].sum()/ megered_tasvieh['total payable'].sum()==10:\n",
    "            print('sum of pay is equal in both files')\n",
    "        #------------------------------------------check name and lastname--------------------------------------#\n",
    "        \n",
    "        #if megered_tasvieh[megered_tasvieh['lastname'].isnull()]:\n",
    "         #   ind = list(merged[merged['lastname'].isnull()].index)\n",
    "          #  merged['lastname'][ind] = merged['name'][ind]\n",
    "        filt = megered_tasvieh['concated_x'] != megered_tasvieh['concated_y']\n",
    "        final_check = megered_tasvieh[filt]\n",
    "        \n",
    "\n",
    "        return megered_tasvieh, self.tasvieh_data , final_check\n",
    "    \n",
    "    '''def calculation(self):\n",
    "        \n",
    "        #length:\n",
    "        if self.tasvieh_data.shape[0] == self.payment_comp.shape[0]:\n",
    "            print('Same number of sheba in both files')\n",
    "            \n",
    "\n",
    "        \n",
    "        self.tasvieh_data['concated']=self.tasvieh_data['sheba number'].apply(str)+'_'+self.tasvieh_data['name'].apply(str)+'_'+self.tasvieh_data['payable'].apply(str)\n",
    "        self.payment_comp['concated']=self.payment_comp['sheba number'].apply(str)+'_'+self.payment_comp['lastname'].apply(str)+'_'+self.payment_comp['rial_payable'].apply(str)\n",
    "        \n",
    "        return self.tasvieh_data , self.payment_comp '''\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc341b06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Same number of sheba in both files\n",
      "sum of pay is equal in both files\n"
     ]
    }
   ],
   "source": [
    "finance = Finance(data= data , path =r'C:\\Users\\snappfood\\Desktop\\financial\\28may - 3jun' , name = 'tasvieh.xlsx')\n",
    "merged,f_df , final_check= finance.calculation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f70e616",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sheba number</th>\n",
       "      <th>name</th>\n",
       "      <th>payable</th>\n",
       "      <th>concated_x</th>\n",
       "      <th>lastname</th>\n",
       "      <th>firstname</th>\n",
       "      <th>total payable</th>\n",
       "      <th>concated_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>IR040170000000336758144007</td>\n",
       "      <td>بهمن ایپکچی</td>\n",
       "      <td>9790000</td>\n",
       "      <td>IR040170000000336758144007_ بهمن ایپکچی_9790000</td>\n",
       "      <td>بهمن ایپکچی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9790000</td>\n",
       "      <td>IR040170000000336758144007_nan بهمن ایپکچی_979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>IR150190000000212739320000</td>\n",
       "      <td>محمد میلاد نوذر</td>\n",
       "      <td>4415000</td>\n",
       "      <td>IR150190000000212739320000_ محمد میلاد نوذر_44...</td>\n",
       "      <td>محمد میلاد نوذر</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4415000</td>\n",
       "      <td>IR150190000000212739320000_nan محمد میلاد نوذر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>IR200700001000113310565001</td>\n",
       "      <td>مهدی بداقی</td>\n",
       "      <td>3000000</td>\n",
       "      <td>IR200700001000113310565001_ مهدی بداقی_3000000</td>\n",
       "      <td>مهدی بداقی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000000</td>\n",
       "      <td>IR200700001000113310565001_nan مهدی بداقی_3000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>IR280540100247000188993609</td>\n",
       "      <td>قربان محمد قزل</td>\n",
       "      <td>10787000</td>\n",
       "      <td>IR280540100247000188993609_ قربان محمد قزل_107...</td>\n",
       "      <td>قربان محمد قزل</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10787000</td>\n",
       "      <td>IR280540100247000188993609_nan قربان محمد قزل_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>IR410120010000005825701150</td>\n",
       "      <td>مسعود مناهی</td>\n",
       "      <td>20945000</td>\n",
       "      <td>IR410120010000005825701150_ مسعود مناهی_20945000</td>\n",
       "      <td>مسعود مناهی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20945000</td>\n",
       "      <td>IR410120010000005825701150_nan مسعود مناهی_209...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>IR480120010000005033073866</td>\n",
       "      <td>سید علی بزرگی دار شیرخانی</td>\n",
       "      <td>25462000</td>\n",
       "      <td>IR480120010000005033073866_ سید علی بزرگی دار ...</td>\n",
       "      <td>سید علی بزرگی دار شیرخانی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25462000</td>\n",
       "      <td>IR480120010000005033073866_nan سید علی بزرگی د...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3177</th>\n",
       "      <td>IR540160000000000826576699</td>\n",
       "      <td>مسعود بزرگی</td>\n",
       "      <td>18300000</td>\n",
       "      <td>IR540160000000000826576699_ مسعود بزرگی_18300000</td>\n",
       "      <td>مسعود بزرگی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18300000</td>\n",
       "      <td>IR540160000000000826576699_nan مسعود بزرگی_183...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>IR540570270110011607819001</td>\n",
       "      <td>امیر یاری</td>\n",
       "      <td>29005000</td>\n",
       "      <td>IR540570270110011607819001_ امیر یاری_29005000</td>\n",
       "      <td>امیر یاری</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29005000</td>\n",
       "      <td>IR540570270110011607819001_nan امیر یاری_29005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>IR570610000000400814053548</td>\n",
       "      <td>علی باقری اصل</td>\n",
       "      <td>1455000</td>\n",
       "      <td>IR570610000000400814053548_ علی باقری اصل_1455000</td>\n",
       "      <td>علی باقری اصل</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1455000</td>\n",
       "      <td>IR570610000000400814053548_nan علی باقری اصل_1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3544</th>\n",
       "      <td>IR600130100000000055755434</td>\n",
       "      <td>جعفر سنگ سفیدی</td>\n",
       "      <td>10098000</td>\n",
       "      <td>IR600130100000000055755434_ جعفر سنگ سفیدی_100...</td>\n",
       "      <td>جعفر سنگ سفیدی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10098000</td>\n",
       "      <td>IR600130100000000055755434_nan جعفر سنگ سفیدی_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580</th>\n",
       "      <td>IR600540122747000325243604</td>\n",
       "      <td>علی علیزاده</td>\n",
       "      <td>750000</td>\n",
       "      <td>IR600540122747000325243604_ علی علیزاده_750000</td>\n",
       "      <td>علی علیزاده</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750000</td>\n",
       "      <td>IR600540122747000325243604_nan علی علیزاده_750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>IR710170000000350569701007</td>\n",
       "      <td>عبدالاحد حسن زاده</td>\n",
       "      <td>460000</td>\n",
       "      <td>IR710170000000350569701007_ عبدالاحد حسن زاده_...</td>\n",
       "      <td>عبدالاحد حسن زاده</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460000</td>\n",
       "      <td>IR710170000000350569701007_nan عبدالاحد حسن زا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>IR910560082088802812339001</td>\n",
       "      <td>مهدی قدیمی</td>\n",
       "      <td>5250000</td>\n",
       "      <td>IR910560082088802812339001_ مهدی قدیمی_5250000</td>\n",
       "      <td>مهدی قدیمی</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5250000</td>\n",
       "      <td>IR910560082088802812339001_nan مهدی قدیمی_5250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sheba number                        name   payable  \\\n",
       "135   IR040170000000336758144007                 بهمن ایپکچی   9790000   \n",
       "836   IR150190000000212739320000             محمد میلاد نوذر   4415000   \n",
       "1152  IR200700001000113310565001                  مهدی بداقی   3000000   \n",
       "1615  IR280540100247000188993609              قربان محمد قزل  10787000   \n",
       "2377  IR410120010000005825701150                 مسعود مناهی  20945000   \n",
       "2804  IR480120010000005033073866   سید علی بزرگی دار شیرخانی  25462000   \n",
       "3177  IR540160000000000826576699                 مسعود بزرگی  18300000   \n",
       "3231  IR540570270110011607819001                   امیر یاری  29005000   \n",
       "3412  IR570610000000400814053548               علی باقری اصل   1455000   \n",
       "3544  IR600130100000000055755434              جعفر سنگ سفیدی  10098000   \n",
       "3580  IR600540122747000325243604                 علی علیزاده    750000   \n",
       "4174  IR710170000000350569701007           عبدالاحد حسن زاده    460000   \n",
       "5428  IR910560082088802812339001                  مهدی قدیمی   5250000   \n",
       "\n",
       "                                             concated_x  \\\n",
       "135     IR040170000000336758144007_ بهمن ایپکچی_9790000   \n",
       "836   IR150190000000212739320000_ محمد میلاد نوذر_44...   \n",
       "1152     IR200700001000113310565001_ مهدی بداقی_3000000   \n",
       "1615  IR280540100247000188993609_ قربان محمد قزل_107...   \n",
       "2377   IR410120010000005825701150_ مسعود مناهی_20945000   \n",
       "2804  IR480120010000005033073866_ سید علی بزرگی دار ...   \n",
       "3177   IR540160000000000826576699_ مسعود بزرگی_18300000   \n",
       "3231     IR540570270110011607819001_ امیر یاری_29005000   \n",
       "3412  IR570610000000400814053548_ علی باقری اصل_1455000   \n",
       "3544  IR600130100000000055755434_ جعفر سنگ سفیدی_100...   \n",
       "3580     IR600540122747000325243604_ علی علیزاده_750000   \n",
       "4174  IR710170000000350569701007_ عبدالاحد حسن زاده_...   \n",
       "5428     IR910560082088802812339001_ مهدی قدیمی_5250000   \n",
       "\n",
       "                       lastname firstname  total payable  \\\n",
       "135                 بهمن ایپکچی       NaN        9790000   \n",
       "836             محمد میلاد نوذر       NaN        4415000   \n",
       "1152                 مهدی بداقی       NaN        3000000   \n",
       "1615             قربان محمد قزل       NaN       10787000   \n",
       "2377                مسعود مناهی       NaN       20945000   \n",
       "2804  سید علی بزرگی دار شیرخانی       NaN       25462000   \n",
       "3177                مسعود بزرگی       NaN       18300000   \n",
       "3231                  امیر یاری       NaN       29005000   \n",
       "3412              علی باقری اصل       NaN        1455000   \n",
       "3544             جعفر سنگ سفیدی       NaN       10098000   \n",
       "3580                علی علیزاده       NaN         750000   \n",
       "4174          عبدالاحد حسن زاده       NaN         460000   \n",
       "5428                 مهدی قدیمی       NaN        5250000   \n",
       "\n",
       "                                             concated_y  \n",
       "135   IR040170000000336758144007_nan بهمن ایپکچی_979...  \n",
       "836   IR150190000000212739320000_nan محمد میلاد نوذر...  \n",
       "1152  IR200700001000113310565001_nan مهدی بداقی_3000000  \n",
       "1615  IR280540100247000188993609_nan قربان محمد قزل_...  \n",
       "2377  IR410120010000005825701150_nan مسعود مناهی_209...  \n",
       "2804  IR480120010000005033073866_nan سید علی بزرگی د...  \n",
       "3177  IR540160000000000826576699_nan مسعود بزرگی_183...  \n",
       "3231  IR540570270110011607819001_nan امیر یاری_29005000  \n",
       "3412  IR570610000000400814053548_nan علی باقری اصل_1...  \n",
       "3544  IR600130100000000055755434_nan جعفر سنگ سفیدی_...  \n",
       "3580  IR600540122747000325243604_nan علی علیزاده_750000  \n",
       "4174  IR710170000000350569701007_nan عبدالاحد حسن زا...  \n",
       "5428  IR910560082088802812339001_nan مهدی قدیمی_5250000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_check"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
